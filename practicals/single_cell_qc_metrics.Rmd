---
title: "Quality control metrics (10X 2.7K PBMCs)"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Goal

- To give you some experience with quality control and how it is used in scRNA-Seq.
- To introduce you to the Seurat analysis environment.

## Introduction

The literature points to scRNA-Seq having interesting characteristic. Although, not fully characterized, two of the characteristics that are important to keep in mind when working with scRNA-Seq is Drop-out and the potential for QC metrics to be confounded with biology. This combined with the ability to see more heterogeniety from cells in samples (than traditional population-based methods) has shifted the field away from, at the time established analysis patterns in population-based RNA-Seq. Here we talk through some approaches initial approaches to quality control metrics.

For this tutorial, we will be analyzing the a dataset of Peripheral Blood Mononuclear Cells (PBMC) freely available from 10X Genomics, using the Seurat R package (http://satijalab.org/seurat/), a popular and powerful set of tools to conduct scRNA-seq analysis in R. In this dataset, there are 2,700 single cells that were sequenced on the Illumina NextSeq 500. 

```{r global_options, echo=FALSE}
knitr::opts_chunk$set(cache=TRUE)
knitr::opts_chunk$set(tidy.opts=list(width.cutoff=80))
```

Load necessary packages

```{r, warning=FALSE, message=FALSE}
library(Seurat)
library(dplyr)
library(Matrix)
source("utilities.R")
```

# **  human peripheral blood mononuclear cells from: https://support.10xgenomics.com/single-cell-gene-expression/datasets
counts_matrix_filename = "data/pbmcs/pbmc3k.counts.matrix.gz"; org="human"

```

##############################
# Data preparation
##############################

```{r}
# Read data from your file, rows as genes colums as cells
myCountMatrix <- read.table(gzfile(counts_matrix_filename), header=T, row.names=1)
```

Look at the matrix:
```{r}
myCountMatrix[1:10, 1:3]
```

How big is the matrix?

```{r}
dim(myCountMatrix) # report num rows and cols
```

Size in bytes?
```{r}
object.size(myCountMatrix)
```

Convert the matrix to a sparse matrix
```{r}
myCountMatrixSparse <- Matrix(as.matrix(myCountMatrix), sparse = T)

# take a look at it:
myCountMatrixSparse[1:10,1:3]
```

```{r}
# check dimensions:
dim(myCountMatrixSparse)

# check size:
object.size(myCountMatrixSparse)

# size reduction:
object.size(myCountMatrixSparse) / object.size(myCountMatrix)

```

```{r}
# Remove the original matrix to reduce memory usage
rm(myCountMatrix)
myCountMatrixSparse.prefiltered = myCountMatrixSparse # store just in case
```

## Filtering 'bad' cells

Look at the summary counts

```{r}
#par(mfrow=c(1,2), mar = c(3.5,3.5,2.0,0.5), mgp = c(2,0.65,0), cex = 1.0)

reads_per_cell = Matrix::colSums(myCountMatrixSparse)
reads_per_gene = Matrix::rowSums(myCountMatrixSparse)
genes_per_cell = Matrix::colSums(myCountMatrixSparse>0) # count gene only if it has non-zero reads mapped.
cells_per_gene = Matrix::rowSums(myCountMatrixSparse>0) # only count cells where the gene is expressed

hist(log10(reads_per_cell+1),main='reads per cell',col='wheat')
hist(log10(genes_per_cell+1), main='genes per cell', col='wheat')
plot(reads_per_cell, genes_per_cell, log='xy', col='wheat')
hist(log10(reads_per_gene+1),main='reads per gene',col='wheat')
```

### Plot genes per cell with cells ranked accordingly.

```{r}
plot(sort(genes_per_cell), xlab='cell', log='y', main='genes per cell (ordered)')

```

### Cell filtering criteria:  define min and max genes per cell

```{r}
#  set upper and lower thresholds for genes per cell:
MIN_GENES_PER_CELL = 350  ## user-defined setting
MAX_GENES_PER_CELL = 1800  ## user-defined setting

# now replot with the thresholds being shown:
plot(sort(genes_per_cell), xlab='cell', log='y', main='genes per cell (ordered)')
abline(h=MIN_GENES_PER_CELL, col='green')  # lower threshold
abline(h=MAX_GENES_PER_CELL, col='green') # upper threshold
```

### Examine percent mitochondrial read content

```{r}
# define the mitochondrial genes
mito_genes = grep("^mt-", rownames(myCountMatrixSparse) , ignore.case=T, value=T)
print(mito_genes)
```

```{r}
# compute pct mito
mito_gene_read_counts = Matrix::colSums(myCountMatrixSparse[mito_genes,])
pct_mito = mito_gene_read_counts / reads_per_cell * 100
plot(sort(pct_mito))
```

Decide on maximum allowed percent mitochondrial reads:

```{r}
MAX_PCT_MITO = 10   ## user-defined setting

plot(sort(pct_mito))
abline(h=MAX_PCT_MITO, col='red')

```

### Plot gene_per_cell vs. reads_per_cell, define outliers

```{r}
library(MASS)
df = df[order(df$reads_per_cell),] # order by reads_per_cell
plot(df, log='xy')
m <- rlm(genes_per_cell~reads_per_cell,data=df) # robust linear model, not sens to outliers
p.level = 1e-3
# predict genes_per_cell based on observed reads_per_cell
suppressWarnings(pb <- data.frame(predict(m, interval='prediction', 
                                          level = 1-p.level, # define conf interval
                                          type="response")))
polygon(c(df$reads_per_cell, rev(df$reads_per_cell)),
        c(pb$lwr, rev(pb$upr)), col=adjustcolor(2,alpha=0.1), border = NA)

# identifier outliers as having observed genes_per_cell outside the prediction confidence interval
outliers <- rownames(df)[df$genes_per_cell > pb$upr | df$genes_per_cell < pb$lwr];
points(df[outliers,],col=2,cex=0.6)
```

###############################################################
# prune cells
valid_cells = colnames(myCountMatrixSparse) # all cells
message('starting with: ', length(valid_cells), ' cells') # number starting with

## remove cells based on gene count criteria:
valid_cells = valid_cells[genes_per_cell >= MIN_GENES_PER_CELL & genes_per_cell <= MAX_GENES_PER_CELL]  # set values based on your evaluation above
message('after filtering low and high gene count outliers: ', length(valid_cells), ' cells') # number after filtering based gene count thresholds

## remove cells having excessive mito read content
valid_cells = valid_cells[valid_cells %in% names(pct_mito)[pct_mito <= MAX_PCT_MITO]]
message('after removing high-mito cells: ', length(valid_cells), ' cells') # number remaining after high-mito cells removed

## remove cells identified as outliers via the Karchenko method
valid_cells = valid_cells[ ! valid_cells %in% outliers]
message('after removing final outliers: ', length(valid_cells), ' cells') # number surviving outlier detection

## update the count matrix to contain only the valid cells
myCountMatrixSparse = myCountMatrixSparse[,valid_cells]
```


-----------
To preprocess their data, 10X genomics provides a software called `cellranger`. `cellranger` aligns the raw reads and generates count matrices. Seurat's `Read10X` function reads these count matrices in the format that 10X provides.


```{r, cache.lazy=FALSE, tidy=TRUE,  tidy.opts=list(width.cutoff=80)}
# Load the PBMC dataset
pbmc.data <- Read10X(data.dir = "filtered_gene_bc_matrices/hg19/")

# Examine the memory savings between regular and sparse matrices
dense.size <- object.size(x = as.matrix(x = pbmc.data))
dense.size
```

Seurat stores the count matrix in the sparse format. For matrices where a majority of the entries are zero, which is generally the case for scRNA-seq data (remember dropouts?), it is far more memory efficient to only remember the non-zero entries of the matrix, rather than the entire matrix (which is mostly zeros). This is essentially the basis of the sparse representation, a format that is supported by all programming languages. Notice below how much memory we save due to the sparse format.


```{r, cache.lazy=FALSE}
sparse.size <- object.size(x = pbmc.data)
sparse.size
```

```{r, cache.lazy=FALSE}
dense.size/sparse.size
```
As is the case in a general R workflow, we center all our analysis on a single "object", in this case an object of the class Seurat that we will call `pbmc`. This object will contain various "slots" that will store not only the raw input data, but also the results from various computations below. This has the advantage that we do not need to keep track of inidividual variables of interest - they can all be collapsed into a single object as long as these slots are pre-defined.

```{r, cache.lazy=FALSE}
# Initialize the Seurat object with the raw (non-normalized data).  Keep all
# genes expressed in >= 3 cells (~0.1% of the data). Keep all cells with at
# least 200 detected genes
pbmc <- CreateSeuratObject(raw.data = pbmc.data, min.cells = 3, min.genes = 200,
                           project = "10X_PBMC")
```

`pbmc@raw.data` is a slot that stores the original gene expression matrix. We can visualize the first 20 rows (genes) and the first 10 columns (cells),
```{r, cache.lazy=FALSE}
pbmc@raw.data[1:20,1:10]
```

## Preprocessing step 1 : Filter out unhealthy cells

The object initialization step above only considered cells that express at least 200 genes. Additionally, we would like to exclude cells that are unhealthy. A common metric to judge this (although by no means the only one ) is the relative expression of mitochondrially derived genes. When the cells apoptose due to stress, their mitochondria becomes leaky and there is widespread RNA-degradation. Thus a relative enrichment of mitochondrially derived genes can be a tell-tale sign of cell stress. Here, we compute the proportion of transcripts that are of mitochondrial origin for every cell (`percent.mito`), and visualize its distribution as a violin plot. We also use the `GenePlot` function to observe how `percent.mito` correlates with other metrics

```{r, cache.lazy=FALSE, tidy=TRUE, tidy.opts=list(width.cutoff=120), fig.width= 12, fig.height=6.5}
# The number of genes and UMIs (nGene and nUMI) are automatically calculated
# for every object by Seurat.  For non-UMI data, nUMI represents the sum of
# the non-normalized values within a cell We calculate the percentage of
# mitochondrial genes here and store it in percent.mito using AddMetaData.
# We use object@raw.data since this represents non-transformed and
# non-log-normalized counts The % of UMI mapping to MT-genes is a common
# scRNA-seq QC metric.
mito.genes <- grep(pattern = "^MT-", x = rownames(x = pbmc@data), value = TRUE)
percent.mito <- Matrix::colSums(pbmc@raw.data[mito.genes, ])/Matrix::colSums(pbmc@raw.data)

# AddMetaData adds columns to object@meta.data, and is a great place to
# stash QC stats
pbmc <- AddMetaData(object = pbmc, metadata = percent.mito, col.name = "percent.mito")
VlnPlot(object = pbmc, features.plot = c("nGene", "nUMI", "percent.mito"), nCol = 3)

# GenePlot is typically used to visualize gene-gene relationships, but can
# be used for anything calculated by the object, i.e. columns in
# object@meta.data, PC scores etc.  Since there is a rare subset of cells
# with an outlier level of high mitochondrial percentage and also low UMI
# content, we filter these as well
par(mfrow = c(1, 2))
GenePlot(object = pbmc, gene1 = "nUMI", gene2 = "percent.mito")
GenePlot(object = pbmc, gene1 = "nUMI", gene2 = "nGene")
```

```{r, cache.lazy=FALSE}
# We filter out cells that have unique gene counts over 2,500 or less than
# 200 Note that low.thresholds and high.thresholds are used to define a
# 'gate' -Inf and Inf should be used if you don't want a lower or upper
# threshold.
pbmc <- FilterCells(object = pbmc, subset.names = c("nGene", "percent.mito"),
    low.thresholds = c(200, -Inf), high.thresholds = c(2500, 0.05))

## Preprocessing step 2 : Expression normalization

After removing unwanted cells from the dataset, the next step is to normalize the data. By default, Seurat a global-scaling normalization method “LogNormalize” that normalizes the gene expression measurements for each cell by the total expression, multiplies this by a scale factor (10,000 by default), and log-transforms the result. There have been many methods to normalize the data, but this is the simplest and the most intuitive. The division by total expression is done to change all expression counts to a relative measure, since experience has suggested that technical factors (e.g. capture rate, efficiency of RT) are largely responsible for the variation in the number of molecules per cell, although genuine biological factors (e.g. cell cycle stage, cell size) also play a smaller, but non-negligible role. The log-transformation is a commonly used transformation that has many desirable properties, such as variance stabilization (can you think of others?).

For a recent review on scRNA-seq normalization, see Vallejos et al., _Nature Methods_, 2017.

```{r, cache.lazy=FALSE}
pbmc <- NormalizeData(object = pbmc, normalization.method = "LogNormalize",
                      scale.factor = 10000)

## Sources

This practical is derived from the following resources, please visit them for updates and more details.

1. Seurat2:  http://satijalab.org/seurat
